### Task to predict whether person has ckd or notckd??

## ckd-chronic kidney disease
## notckd-->> not crornic kidney disease


import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv(r'F:\Machine Learning\Projects\Chronic Kidney Disease/kidney_disease.csv')
df.head()

df.shape

    1. Features:
    age - age
    bp - blood pressure
    sg - specific gravity
    al - albumin
    su - sugar
    rbc - red blood cells
    pc - pus cell
    pcc - pus cell clumps
    ba - bacteria
    bgr - blood glucose random
    bu - blood urea
    sc - serum creatinine
    sod - sodium
    pot - potassium
    hemo - haemoglobin
    pcv - packed cell volume
    wc - white blood cell count
    rc - red blood cell count
    htn - hypertension
    dm - diabetes mellitus
    cad - coronary artery disease
    appet - appetite
    pe - pedal edema
    ane - anemia
    classification - class

### rename column names to make it more user-friendly

columns=pd.read_csv('F:\Machine Learning\Projects\Chronic Kidney Disease/data_description.txt',sep='-')
columns=columns.reset_index()
columns.columns=['cols','abb_col_names']

columns

df.head()

df.columns=columns['abb_col_names'].values

df

df.dtypes

    As it can be seen, red_blood_cell_count, packed_cell_volume and white_blood_cell_count are object type. We need to 
    change to numerical dtype.

features=['red_blood_cell_count','packed_cell_volume','white_blood_cell_count']

def convert_dtype(df,feature):
    df[feature] = pd.to_numeric(df[feature], errors='coerce')

for feature in features:
    convert_dtype(df,feature)



    Let's drop the id column. id column is seems to be an unique identifier for each row so we are dropping that it won't 
    help us to find any insights from the data

df.drop(["id"],axis=1,inplace=True) 

### Extract Numerical & Categorical Features

def extract_cat_num(df):
    cat_col=[col for col in df.columns if df[col].dtype=='object']
    num_col=[col for col in df.columns if df[col].dtype!='object']
    return cat_col,num_col

cat_col,num_col=extract_cat_num(df)

cat_col

num_col

### total unique categories in our categorical features to check if any dirtiness in data or not

for col in cat_col:
    print('{} has {} values '.format(col,df[col].unique()))
    print('\n')

## ckd-chronic kidney disease
## notckd-->> not crornic kidney disease



    So we need to correct 2 features and the target variable which contain certain discrepancy in some values.

#Replace incorrect values

df['diabetes_mellitus'].replace(to_replace = {'\tno':'no','\tyes':'yes',' yes':'yes'},inplace=True)

df['coronary_artery_disease'] = df['coronary_artery_disease'].replace(to_replace = '\tno', value='no')

df['classification'] = df['classification'].replace(to_replace = 'ckd\t', value = 'ckd')

for col in cat_col:
    print('{} has {} values  '.format(col, df[col].unique()))
    print('\n')

    Looks good now apart from the NaNs

len(num_col)



###  Checking features distribution

plt.figure(figsize=(30,20))
for i,feature in enumerate(num_col):
    plt.subplot(5,3,i+1)
    df[feature].hist()
    plt.title(feature)



    Observations:
        1.age looks a bit left skewed
        2.Blood gluscose random is right skewed
        3.Blood Urea is also a bit right skewed
        4.Rest of the features are lightly skewed

### Now, let's check the label distribution for categorical data

len(cat_col)

plt.figure(figsize=(20,20))
for i,feature in enumerate(cat_col):
    plt.subplot(4,3,i+1)
    sns.countplot(df[feature])
    



    A few features have imbalanced categories. Stratified folds will be necessary while cross validation.

sns.countplot(x='classification',data=df)
plt.xlabel("classification")
plt.ylabel("Count")
plt.title("target Class")

## ckd-chronic kidney disease
## notckd-->> not crornic kidney disease

###  7. Correlations

plt.figure(figsize=(10,8))
corr_df = df.corr()
sns.heatmap(corr_df,annot=True)

    Positive Correlation:
    
    Specific gravity -> Red blood cell count, Packed cell volume and Hemoglobin
    Sugar -> Blood glucose random
    Blood Urea -> Serum creatinine
    Hemoglobin -> Red Blood cell count <- packed cell volume
    
    
    Negative Correlation:
    Albumin, Blood urea -> Red blood cell count, packed cell volume, Hemoglobin
    Serum creatinine -> Sodium

df.groupby(['red_blood_cells','classification'])['red_blood_cell_count'].agg(['count','mean','median','min','max'])

### Let's check for Positive correlation and its impact on classesÂ¶

import plotly.express as px

px.violin(df,y='red_blood_cell_count',x="classification", color="classification")

px.scatter(df,'haemoglobin','packed_cell_volume')

### analysing distribution of 'red_blood_cell_count' in both Labels 

grid=sns.FacetGrid(df, hue="classification",aspect=2)
grid.map(sns.kdeplot, 'red_blood_cell_count')
grid.add_legend()

    Both distributions are quite different, distribution CKD is quite normal and evenly distributed but not CKD distribution is a little bit left-skewed but quite close to a normal distribution







# Defining violin and scatter plot & kde_plot functions
def violin(col):
    fig = px.violin(df, y=col, x="classification", color="classification", box=True)
    return fig.show()

def scatters(col1,col2):
    fig = px.scatter(df, x=col1, y=col2, color="classification")
    return fig.show()

def kde_plot(feature):
    grid = sns.FacetGrid(df, hue="classification",aspect=2)
    grid.map(sns.kdeplot, feature)
    grid.add_legend()

kde_plot('red_blood_cell_count')

kde_plot('haemoglobin')





scatters('red_blood_cell_count', 'packed_cell_volume')

scatters('red_blood_cell_count', 'haemoglobin')

scatters('haemoglobin','packed_cell_volume')

    1.RBC count range ~2 to <4.5 and Hemoglobin between 3 to <13 are mostly classified as positive for chronic kidney  
    disease(i.e ckd).
    2.RBC count range >4.5 to ~6.1 and Hemoglobin between >13 to 17.8 are classified as negative for chronic kidney 
    disease(i.e nockd).



violin('red_blood_cell_count')

violin('packed_cell_volume')



###  Now let's check for negative correlation and its impact on classes

    Albumin, Blood urea -> Red blood cell count, packed cell volume, Haemoglobin

scatters('red_blood_cell_count','albumin')

    Clearly, albumin levels of above 0 affect ckd largely

scatters('packed_cell_volume','blood_urea')

    Packed cell volume >= 40 largely affects to be non ckd

fig = px.bar(df, x="specific_gravity", y="packed_cell_volume",
             color='classification', barmode='group',
             height=400)
fig.show()

    Clearly, specific gravity >=1.02 affects non ckd



df.head()

df.isna().sum().sort_values(ascending=False)



cat_col

sns.countplot(df['red_blood_cells'])

data=df.copy()



### filling missing with Random value

#### Random Value Imputation

data['red_blood_cells'].isnull().sum()

data['red_blood_cells'].dropna().sample()

random_sample=data['red_blood_cells'].dropna().sample(data['red_blood_cells'].isnull().sum())
random_sample

random_sample.index

data[data['red_blood_cells'].isnull()].index

random_sample.index=data[data['red_blood_cells'].isnull()].index

random_sample.index

random_sample

data.loc[data['red_blood_cells'].isnull(),'red_blood_cells']=random_sample

data.head()

sns.countplot(data['red_blood_cells'])

data['red_blood_cells'].value_counts()/len(data)

len(df[df['red_blood_cells']=='normal'])/248

len(df[df['red_blood_cells']=='abnormal'])/248

### lets create a function so that I can easily do it for all features
def Random_value_imputation(feature):
    random_sample=data[feature].dropna().sample(data[feature].isnull().sum())               
    random_sample.index=data[data[feature].isnull()].index
    data.loc[data[feature].isnull(),feature]=random_sample



Random_value_imputation('pus_cell')
Random_value_imputation('red_blood_cells')

data[cat_col].isnull().sum()

### as rest of the features has less missing values,so I can fill it using mode concept

mode=data['pus_cell_clumps'].mode()[0]
mode


data['pus_cell_clumps']=data['pus_cell_clumps'].fillna(mode)

def impute_mode(feature):
    mode=data[feature].mode()[0]
    data[feature]=data[feature].fillna(mode)

for col in cat_col:
    impute_mode(col)

data[cat_col].isnull().sum()

data[num_col].isnull().sum()

### lets fill missing values in Numerical features using Random value Imputation

for col in num_col:
    Random_value_imputation(col)

data[num_col].isnull().sum()



### feature Encoding

for col in cat_col:
    print('{} has {} categories'.format(col, data[col].nunique()))
    

#### as we have just 2 categories in each feature then we can consider Label Encoder as it will not cause Curse of Dimensionality

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

for col in cat_col:
    data[col]=le.fit_transform(data[col])

data.head()



### Feature Importance


#SelectKBest-to select k best features

#chi2-Internally this class is going to check that whether p-value is less than 0.05 or not
#based on that,it will actually order all the features

from sklearn.feature_selection import SelectKBest#Also known as Information Gain
from sklearn.feature_selection import chi2



ind_col=[col for col in data.columns if col!='classification']
dep_col='classification'

X=data[ind_col]
y=data[dep_col]


ordered_rank_features=SelectKBest(score_func=chi2,k=20)
ordered_feature=ordered_rank_features.fit(X,y)

ordered_feature

#To get scores(rank) of feature,what we can do we can use scores function
ordered_feature.scores_

datascores=pd.DataFrame(ordered_feature.scores_,columns=["Score"])
datascores

dfcolumns=pd.DataFrame(X.columns)
dfcolumns

features_rank=pd.concat([dfcolumns,datascores],axis=1)

features_rank

#Higher the score is,more important feature is 

features_rank.columns=['Features','Score']
features_rank

#fetch largest 10 values of Score column
features_rank.nlargest(10,'Score')

selected_columns=features_rank.nlargest(10,'Score')['Features'].values

X_new=data[selected_columns]



### Model Building

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_new,y,train_size=0.75)

print(X_train.shape)
print(X_test.shape)

## check whether dataset is imbalance or not
y_train.value_counts()

### Lets find best model using Hyperparameter optimization

from xgboost import XGBClassifier
XGBClassifier()

## Hyper Parameter Optimization with respect to XGBoost

params={
 "learning_rate"    : [0.05, 0.20, 0.25 ] ,
 "max_depth"        : [ 5, 8, 10, 12],
 "min_child_weight" : [ 1, 3, 5, 7 ],
 "gamma"            : [ 0.0, 0.1, 0.2 , 0.4 ],
 "colsample_bytree" : [ 0.3, 0.4, 0.7 ]
    
}

from sklearn.model_selection import RandomizedSearchCV

from xgboost import XGBClassifier
classifier=XGBClassifier()

import warnings
from warnings import filterwarnings
filterwarnings('ignore')

random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)

random_search.fit(X_train, y_train)

random_search.best_estimator_

random_search.best_params_



classifier=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=0.4, gamma=0.0, gpu_id=-1,
              importance_type='gain', interaction_constraints='',
              learning_rate=0.25, max_delta_step=0, max_depth=5,
              min_child_weight=1, monotone_constraints='()',
              n_estimators=100, n_jobs=2, num_parallel_tree=1,
              objective='binary:logistic', random_state=0, reg_alpha=0,
              reg_lambda=1, scale_pos_weight=1, subsample=1,
              tree_method='exact', use_label_encoder=True,
              validate_parameters=1, verbosity=None)

## we have got this model on the basis of cross valudation & hyper-parameter optimization

classifier.fit(X_train,y_train)



y_pred=classifier.predict(X_test)

from sklearn.metrics import confusion_matrix,accuracy_score

confusion = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:')
print(confusion)

### to make confusion matrix user-friendly
plt.imshow(confusion)

accuracy_score(y_test, y_pred)















